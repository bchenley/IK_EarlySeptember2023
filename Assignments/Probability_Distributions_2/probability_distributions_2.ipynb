{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "from matplotlib import pyplot as plt, colors as mcolors, gridspec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 \n",
    "\n",
    "Investigate the impact of sample size on the t-distribution through a Python program. Generate random samples of varying sizes from a standard normal distribution, compute t-statistics, and visually track the evolution of the t-distribution with increasing sample size. Provide an analysis report on the interpretation of the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "X = np.arange(-4, 4.01, 8/100)\n",
    "Z = ss.norm(0, 1).pdf(X)\n",
    "\n",
    "plt.plot(X, Z, 'k', label = 'N(0,1)')\n",
    "\n",
    "samples_sizes = [10, 100, 1000]\n",
    "\n",
    "t = []\n",
    "\n",
    "for n in samples_sizes:  \n",
    "\n",
    "    # Generate random samples of size n from a standard normal distribution\n",
    "    X = np.random.normal(loc = 0, scale = 1, size = (n, 1000))\n",
    "    \n",
    "    X_mean = X.mean(0) # 1000 samples means\n",
    "    X_std = X.std(0) # 1000 samples sdevs\n",
    "\n",
    "    t_n = np.array(X_mean / (X_std / np.sqrt(n))) # 1000 t-statistics for sample size n\n",
    "\n",
    "    t.append(t_n)\n",
    "    \n",
    "    # plt.hist(t_n, alpha = 0.5, density = True)    \n",
    "    sns.kdeplot(t_n, label = f\"n = {n}\")\n",
    "\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Density')\n",
    "plt.xlim([-5, 5])\n",
    "plt.grid()\n",
    "plt.legend() ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis Report**\n",
    "\n",
    "The Figure above shows the theoretical standarn normal distribution (black), along with three distrubtions of t-statistics computed from 1000 random samples of sizes 10 (blue), 100 (orange), and 1000 (green). As the sample size increased, the height of the two tails of the t-distribution decreased. In other words, increasing the sample size led to fewer observations of large values, indicating reduced variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 \n",
    "\n",
    "Simulate a dynamic Beta distribution representing the evolving conversion rate of a website based on user interactions. Visualize the changing distribution over multiple time steps. Provide a detailed analysis report interpreting the plots and insights gained from the dynamic Beta simulation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = conversion, b = no conversion\n",
    "\n",
    "def simulate_dynamic_beta(N = 100, init_a = 1, init_b = 1):\n",
    "\n",
    "    a, b = init_a, init_b\n",
    "    \n",
    "    expected_p = []\n",
    "    conversion = []\n",
    "    param = []\n",
    "    for n in range(N):\n",
    "        \n",
    "        # Expected probability of conversion\n",
    "        expect_p_n = a/(a+b)\n",
    "\n",
    "        # Conversion at n_th step (1 (yes) or 0 (no))\n",
    "        conversion_n = ss.bernoulli(p = expect_p_n).rvs()\n",
    "        \n",
    "        # Update success (a) and failure (b) parameters\n",
    "        a, b = a+conversion_n, b+(1-conversion_n)    \n",
    "\n",
    "        # collect results\n",
    "        expected_p.append(expect_p_n)\n",
    "        conversion.append(conversion_n)\n",
    "        param.append((a, b))\n",
    "    \n",
    "    expected_p = np.stack(expected_p)\n",
    "    conversion = np.stack(conversion)\n",
    "    param = np.stack(param)\n",
    "    \n",
    "    return param, conversion, expected_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## User #1\n",
    "a1, b1 = 5, 5\n",
    "\n",
    "## User #2\n",
    "a2, b2 = 2, 8\n",
    "\n",
    "## User #3\n",
    "a3, b3 = 8, 2\n",
    "\n",
    "N = 200\n",
    "\n",
    "param_1, conversion_1, expected_p_1 = simulate_dynamic_beta(N, init_a = a1, init_b = b1)    \n",
    "param_2, conversion_2, expected_p_2 = simulate_dynamic_beta(N, init_a = a2, init_b = b2)\n",
    "param_3, conversion_3, expected_p_3 = simulate_dynamic_beta(N, init_a = a3, init_b = b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = np.arange(0, 1.01, .01)\n",
    "\n",
    "t = np.arange(N)\n",
    "\n",
    "X, Y = np.meshgrid(x, t)\n",
    "\n",
    "cum_N = np.arange(1, N+1)\n",
    "\n",
    "conversion_rate_1 = conversion_1.cumsum()/cum_N\n",
    "conversion_rate_2 = conversion_2.cumsum()/cum_N\n",
    "conversion_rate_3 = conversion_3.cumsum()/cum_N\n",
    "\n",
    "Z_1 = np.array([ss.beta.pdf(x, a, b) for a, b in param_1])\n",
    "Z_2 = np.array([ss.beta.pdf(x, a, b) for a, b in param_2])\n",
    "Z_3 = np.array([ss.beta.pdf(x, a, b) for a, b in param_3])\n",
    "\n",
    "fig = plt.figure(figsize=(20, 6))  # Adjust the figsize to accommodate the colorbar\n",
    "\n",
    "gs = gridspec.GridSpec(2, 4, width_ratios = [1, 1, 1, 0.05])\n",
    "\n",
    "cmap = 'coolwarm'\n",
    "vmax = 8\n",
    "\n",
    "# Create subplots\n",
    "\n",
    "ax00 = fig.add_subplot(gs[0,0])\n",
    "ax01 = fig.add_subplot(gs[0,1])\n",
    "ax02 = fig.add_subplot(gs[0,2])\n",
    "ax10 = fig.add_subplot(gs[1,0])\n",
    "ax11 = fig.add_subplot(gs[1,1]) # Share y-axis with ax1\n",
    "ax12 = fig.add_subplot(gs[1,2]) # Share y-axis with ax1\n",
    "ax13 = fig.add_subplot(gs[1,3])\n",
    "\n",
    "# Plot with pcolormesh\n",
    "plot00 = ax00.plot(t, conversion_rate_1)\n",
    "plot01 = ax01.plot(t, conversion_rate_2)\n",
    "plot02 = ax02.plot(t, conversion_rate_3)\n",
    "\n",
    "surf10 = ax10.pcolormesh(Y, X, Z_1, cmap=cmap, vmin=0, vmax=vmax)\n",
    "surf11 = ax11.pcolormesh(Y, X, Z_2, cmap=cmap, vmin=0, vmax=vmax)\n",
    "surf12 = ax12.pcolormesh(Y, X, Z_3, cmap=cmap, vmin=0, vmax=vmax)\n",
    "\n",
    "# Set titles and labels\n",
    "ax00.set_title(f\"User #1: Initial (α,β) = {a1, b1}\", fontsize=20)\n",
    "ax01.set_title(f\"User #2: Initial (α,β) = {a2, b2}\", fontsize=20)\n",
    "ax02.set_title(f\"User #3: Initial (α,β) = {a3, b3}\", fontsize=20)\n",
    "\n",
    "for ax in [ax00, ax01, ax02, ax10, ax11, ax12]:\n",
    "    ax.grid(True)\n",
    "    ax.set_xlim([0, t.max()])\n",
    "    ax.set_ylim([0, 1.01])\n",
    "    ax.set_xticks(np.arange(0, t.max()+20, 20))\n",
    "    if ax in [ax10, ax11, ax12]:\n",
    "        ax.set_xlabel('Time Step', fontsize=16)\n",
    "\n",
    "ax00.set_ylabel('Conversion Rate', fontsize=16)\n",
    "ax10.set_ylabel('Prob. of Conversion', fontsize=16)\n",
    "\n",
    "# Add colorbar to the figure, associating it with all three subplots\n",
    "cbar = fig.colorbar(surf12, cax = ax13, label='Density', aspect=20)\n",
    "cbar.set_label('Density', size=20)\n",
    "cbar.ax.tick_params(labelsize=16)\n",
    "\n",
    "plt.tight_layout() ;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis Report**\n",
    "The figure above shows the ratio of the number of conversions relative to the number of interactions (top row) and probability of conversion modeled by the Beta distribution (bottom row) for three users with different initial Beta parameters. User #1 had a balaced success/failure state (α=β=0), User #2 was failure prone (α=2,b=8), and User #3 was success prone (α=8, β=2). For initial time steps, there is greater variability in both the conversion ratio and probability of conversion. However, as time evolves, the conversion ratio and probabilities stabilize.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 \n",
    "\n",
    "You are a data scientist working for an e-commerce company. Recently, the user interface team redesigned the product page, and they want to know if the new design has made any difference in the average time users spend on that page. They provide you with two datasets: one containing the time (in seconds) users spent on the product page before the redesign (pre_redesign_times.csv), and the other containing the time users spent after the redesign (post_redesign_times.csv). Using the F-distribution, can you determine if there's a statistically significant difference in the variances of user engagement times between the two designs? Write a Python program to conduct this hypothesis test, compute the F-statistic, calculate the associated p-value, and draw a conclusion based on a significance level of 0.05. Display your findings visually to make it comprehensible for the UI team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Number of samples\n",
    "n_samples = 1000\n",
    "\n",
    "# Simulating engagement times before redesign\n",
    "mean_pre = 300\n",
    "std_dev_pre = 50\n",
    "pre_redesign_times = np.random.normal(mean_pre, std_dev_pre, n_samples)\n",
    "\n",
    "# Simulating engagement times after redesign\n",
    "mean_post = 310\n",
    "std_dev_post = 60\n",
    "post_redesign_times = np.random.normal(mean_post, std_dev_post, n_samples)\n",
    "\n",
    "# Save to CSV\n",
    "df_pre = pd.DataFrame({'time': pre_redesign_times})\n",
    "df_pre.to_csv('pre_redesign_times.csv', index=False)\n",
    "\n",
    "df_post = pd.DataFrame({'time': post_redesign_times})\n",
    "df_post.to_csv('post_redesign_times.csv', index=False)\n",
    "\n",
    "print(\"Files 'pre_redesign_times.csv' and 'post_redesign_times.csv' created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_ratio_test(group1, group2):\n",
    "    \n",
    "    var1, var2 = group1.var(ddof = 1), group2.var(ddof = 1)\n",
    "    n1, n2 = group1.size, group2.size\n",
    "    \n",
    "    if var1 > var2:\n",
    "        dfn, dfd = n1, n2\n",
    "        F = var1 / var2\n",
    "    else:\n",
    "        dfn, dfd = n2, n1\n",
    "        F = var2 / var1\n",
    "    \n",
    "    p = ss.f.sf(F, dfn, dfd)\n",
    "    return F, p\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By hand\n",
    "F, p_F = f_ratio_test(df_pre['time'], df_post['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AB = pd.concat([df_pre.assign(design = 'pre'),\n",
    "                   df_post.assign(design = 'post')])\n",
    "\n",
    "# Plotting\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Boxplot for visualizing variance\n",
    "ax1 = fig.add_subplot(121)\n",
    "sns.boxplot(x = 'design', y = 'time', data = df_AB, ax = ax1) ;\n",
    "ax1.grid(True)\n",
    "ax1.set_ylabel('Engagement Time [Seconds]', fontsize = 14)\n",
    "ax1.set_xticks(ticks = [0, 1], labels = [\"Pre-Redisgn\", \"Post-Redsign\"])\n",
    "ax1.set_xlabel(None)\n",
    "\n",
    "# Overlaying with density plot\n",
    "ax2 = fig.add_subplot(122)\n",
    "sns.kdeplot(data = df_pre['time'], label = 'Pre-Redesign', fill = True, alpha = 0.3, ax = ax2)\n",
    "sns.kdeplot(data = df_post['time'], label = 'Post-Redesign', fill = True, alpha = 0.3, ax = ax2)\n",
    "ax2.grid(True)\n",
    "ax2.set_xlabel('Engagement Time [Seconds]', fontsize = 14)\n",
    "ax2.set_ylabel('Density', fontsize = 14)\n",
    "ax2.legend(labels = [f\"$σ_{{pre}}$ = {df_pre['time'].std(ddof = 1):.2f} sec\", \n",
    "                     f\"$σ_{{post}}$ = {df_post['time'].std(ddof = 1):.2f} sec\"])\n",
    "\n",
    "# Annotating with F-statistic and P-value\n",
    "plt.title(f\"User Engagement Time Before and After Redesign\\n\"\n",
    "          f\"F-statistic: {F:.2f}, P-value: {p_F:.10f}\", fontsize = 14) ; \n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "There is a statistically significant difference between the variances of the pre-design ($σ_{pre}$ = 51.51 sec) and post-design user ($σ_{post}$ = 58.15 sec) engagement times (F = 1.27, p < 0.001)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IK Environment",
   "language": "python",
   "name": "ikenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
